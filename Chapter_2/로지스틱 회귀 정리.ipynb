{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea7e5560-5dc0-4459-84ae-e5d6e24a00a1",
   "metadata": {},
   "source": [
    "#  🖥️ Introduction\n",
    "---\n",
    "    여기까지 달려오시느라 고생많으셨습니다.🚗 처음 공부해보면 머리가 조금 복잡할거에요.  \n",
    "    이해가 되지 않더라도 여러번 읽다보면 어느 순간 아하! 하는 순간이 올거에요!😝  \n",
    "    그럼 이번 시간엔 지금까지 학습 했던 내용을 정리해볼게요!  \n",
    "---\n",
    "## 🧭 Course\n",
    "- Supervised Learning (Chapter 2)\n",
    "    - 1차시 : Logistic Regression  \n",
    "    - 2차시 : Stochastic Gradient Descen\n",
    "---\n",
    "## ⌛️ 각 차시별 요약\n",
    "1) Logistic Regression (Classification)\n",
    "    1) Definition\n",
    "        - 로지스틱 회귀는 이름은 회귀이지만 분류 모델이다.\n",
    "        - 통상 예측해야하는 결과 값이 두가지 중 하나일때 사용합니다. (이진 분류 문제 해결)\n",
    "        - 하지만 다중 로지스틱 모델도 사용할 수 있는데 여기서 사용하는 활성화함수가 서로 다릅니다.\n",
    "        - (활성화 함수란?) 단순한 선형 모델에서 벗어나 복잡한 패턴을 학습할 수 있도록 만들어줍니다. 뉴런의 입장에서 이 값은 중요하니깐, 활성화하자 or 이 값은 중요하지 않으니깐 무시하자 같은 내용을 결정하는 스위치 역할을 합니다.\n",
    "    2) Sigmoid Function\n",
    "        - $f(x)=\\frac{1}{1+e^{-x}}$\n",
    "    3) Python Libirary\n",
    "        - ```python\n",
    "            from sklearn.linear_model import LogisticRegression\n",
    "            from sklearn.linear_model import LogisticRegressionCV\n",
    "          ```\n",
    "    4) Logistic Regression Parameters (basic=default)\n",
    "        1. penalty='l2'\n",
    "            - penalty : {'l1', 'l2', 'elasticnet', None} # 정규화 방법\n",
    "        3. dual=False\n",
    "            - dual : {'True', 'False'} # 이중 최적화 문제 사용 여부\n",
    "        5. tol=0.0001\n",
    "            - tol : {float} # 수렴 기준을 설정 - 가중치 변화가 이 값보다 작으면 종료\n",
    "        7. C=1.0\n",
    "            - C : {float} # 정규화 강도, 값이 클수록 정규화 효과 적어짐\n",
    "        8. fit_intercept=True\n",
    "            - fit_intercept : {'True', 'Fale'} # 절편을 모델에 포함할지의 여부\n",
    "        9. intercept_scaling=1\n",
    "            - intercept_scaling : {float} # 다중 클래스 문제에서 절편의 스케일을 조정\n",
    "        10. class_weight=None\n",
    "            - class_weight = {dict or 'balanced'} # 각 클래스의 가중치 설정\n",
    "        11. random_state=None\n",
    "            - random_state : {int} # 랜덤 시드 설정\n",
    "        12. solver='lbfgs'\n",
    "            - solver : {'lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'} # 최적화 알고리즘 설정\n",
    "            - 'lbfgs'           'l2', None                     yes\n",
    "            - 'liblinear'       'l1', 'l2'                     no\n",
    "            - 'newton-cg'       'l2', None                     yes\n",
    "            - 'newton-cholesky' 'l2', None                     no\n",
    "            - 'sag'             'l2', None                     yes\n",
    "            - 'saga'            'elasticnet', 'l1', 'l2', None yes\n",
    "        13. max_iter=100\n",
    "            - max_iter : {int} # 최적화 과정에서 허용되는 최대 반복 횟수\n",
    "        14. multi_class='deprecated'\n",
    "            - multi_class : {'auto', 'ovr', 'multinomial'} # 다중 클래스 문제 설정\n",
    "        15. verbose=0\n",
    "            - verbose : {int} # 출력되는 메시지의 양 설정\n",
    "        16. warm_start=False\n",
    "            - warm_start : {'True', 'False'} # 이전 학습 결과의 재사용 여부 결정\n",
    "        17. n_jobs=None\n",
    "            - n_jobs : {int} # 병렬 처리할 작업의 수를 설정\n",
    "        18. l1_ratio=None\n",
    "            - l1_ratio : {float} # l1과 l2 정규화의 비율 설정\n",
    "---\n",
    "    이렇게 많은 파라미터가 존재하는데, 어떤 모델이 이 데이터에 적합한지는 어떻게 찾는 걸까요?\n",
    "    혹시 train_test_split을 불러왔던 곳 기억하나요?\n",
    "    - GridSearchCV 라이브리러가 존재합니다.\n",
    "    - 저희가 모델을 지정하고, 가능한 파라미터값들을 제공하고 난 후에 데이터값을 주면 최적의 모델 조합을 추출해주는거죠!\n",
    "    - 대부분 데이터에 대한 분석이 어느정도 되고 사용해야 될 모델에 대한 갈피가 잡혔을 때 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "1ad82680-29f3-4d70-a81f-2fe99670e43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가장 좋은 모델은 : LogisticRegression(C=1000, solver='newton-cg')\n",
      "그럴 때 정확도는 : 0.9671409028727771\n"
     ]
    }
   ],
   "source": [
    "# 후 발생하는 경고 무시\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# 대표적인 데이터셋 두개를 다뤄볼게요.\n",
    "# 먼저 이진 분류가 사용되는 유방암 데이터입니다.\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer_input = load_breast_cancer().data\n",
    "cancer_target = load_breast_cancer().target\n",
    "\n",
    "# stratify를 사용해서 타깃데이터를 기반으로 공정하게 나누도록 하겠습니다.\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_input, test_input, train_target, test_target = train_test_split(cancer_input,\n",
    "                                                                      cancer_target,\n",
    "                                                                      stratify=cancer_target)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# params에 변화시키고 싶은 값들을 넣습니다\n",
    "params = {\n",
    "    'solver' : ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'],\n",
    "    'penalty' : ['l1', 'l2', 'elasticnet', None],\n",
    "    'C' : [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "}\n",
    "lr = LogisticRegression()\n",
    "# estimator은 적용할 모델이고 param_grid는 적용할 파라미터이고, scoring는 어떤 점수를 기반할 것인지, \n",
    "# cv는 교차 검증 개수를 의미하는데 5의 의미는 데이터를 5개로 나눠서 이를 바탕으로 훈련데이터, 테스트 데이터 나눠서 학습시키는 것을 의미한다.\n",
    "gs = GridSearchCV(estimator=lr,\n",
    "                 param_grid=params,\n",
    "                 scoring='accuracy',\n",
    "                 cv=5)\n",
    "gs.fit(train_input, train_target)\n",
    "print('가장 좋은 모델은 : {}'.format(gs.best_estimator_))\n",
    "print('그럴 때 정확도는 : {}'.format(gs.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "07a3df2b-4387-4546-8934-9cc87af4d9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터에 대한 점수 : 0.9131455399061033\n",
      "테스트 데이터 대한 점수 : 0.958041958041958\n",
      "훈련 데이터에 대한 점수 : 0.9248826291079812\n",
      "테스트 데이터 대한 점수 : 0.965034965034965\n",
      "훈련 데이터에 대한 점수 : 0.9530516431924883\n",
      "테스트 데이터 대한 점수 : 0.965034965034965\n",
      "훈련 데이터에 대한 점수 : 0.9741784037558685\n",
      "테스트 데이터 대한 점수 : 0.958041958041958\n",
      "훈련 데이터에 대한 점수 : 0.9882629107981221\n",
      "테스트 데이터 대한 점수 : 0.972027972027972\n"
     ]
    }
   ],
   "source": [
    "# C가 1000이고, penalty가 l1, solver가 liblinear일때 가장 좋은 성과를 내는군요!\n",
    "# liblinear은 이진분류일때 사용합니다.\n",
    "# 그럼 한번 적용시켜볼까요?\n",
    "# 하지만, C가 1000이면 과적합이 발생할 가능성이 있으니 C는 다시 한번 해볼까요?\n",
    "train_score = []\n",
    "test_score = []\n",
    "C = [0.01, 0.1, 1, 10, 100]\n",
    "for i in C:\n",
    "    lr = LogisticRegression(penalty='l1', \n",
    "                            solver='liblinear',\n",
    "                            C=i)\n",
    "    lr.fit(train_input, train_target)\n",
    "    print('훈련 데이터에 대한 점수 : {}'.format(lr.score(train_input, train_target)))\n",
    "    print('테스트 데이터 대한 점수 : {}'.format(lr.score(test_input, test_target)))\n",
    "    train_score.append(lr.score(train_input, train_target))\n",
    "    test_score.append(lr.score(test_input, test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "ddd45cc3-b691-41b5-b34c-d42ec58c5d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터에 대한 점수 : 0.9765258215962441\n",
      "테스트 데이터 대한 점수 : 0.958041958041958\n"
     ]
    }
   ],
   "source": [
    "# C가 10일때 과적합도 아니고, 과소적합도 아니군요!\n",
    "# 어떤가요? 감이 좀 잡히시나요?\n",
    "lr = LogisticRegression(penalty='l1', \n",
    "                            solver='liblinear',\n",
    "                            C=10)\n",
    "lr.fit(train_input, train_target)\n",
    "print('훈련 데이터에 대한 점수 : {}'.format(lr.score(train_input, train_target)))\n",
    "print('테스트 데이터 대한 점수 : {}'.format(lr.score(test_input, test_target)))\n",
    "data = np.round(lr.decision_function(test_input[:5]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "92dd2d25-9fcd-435a-9b65-8b1363b74a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가장 좋은 모델은 : LogisticRegression(C=0.001, penalty=None, solver='sag')\n",
      "그럴 때 정확도는 : 0.9739130434782609\n"
     ]
    }
   ],
   "source": [
    "# 이번에는 iris 데이터셋을 사용해볼까요?\n",
    "from sklearn.datasets import load_iris\n",
    "iris_input = load_iris().data\n",
    "iris_target = load_iris().target\n",
    "\n",
    "train_input, test_input, train_target, test_target = train_test_split(iris_input,\n",
    "                                                                      iris_target,\n",
    "                                                                      stratify=iris_target)\n",
    "params = {\n",
    "    'solver' : ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'],\n",
    "    'penalty' : ['l1', 'l2', 'elasticnet', None],\n",
    "    'C' : [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "}\n",
    "lr = LogisticRegression()\n",
    "gs = GridSearchCV(estimator=lr,\n",
    "                 param_grid=params,\n",
    "                 scoring='accuracy',\n",
    "                 cv=5)\n",
    "gs.fit(train_input, train_target)\n",
    "print('가장 좋은 모델은 : {}'.format(gs.best_estimator_))\n",
    "print('그럴 때 정확도는 : {}'.format(gs.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "abee0a03-e433-4629-a3d2-666c121cb44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적의 훈련 점수는 : 0.9732142857142857\n",
      "최적의 테스트 점수는 : 1.0\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(penalty='l1', solver='saga', C=1)\n",
    "lr.fit(train_input, train_target)\n",
    "print('최적의 훈련 점수는 : {}'.format(lr.score(train_input, train_target)))\n",
    "print('최적의 테스트 점수는 : {}'.format(lr.score(test_input, test_target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "e28fe5b5-8ff9-4a22-a133-fbd496166682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가장 좋은 모델은 : LogisticRegressionCV(penalty='l1', solver='saga')\n",
      "그럴 때 정확도는 : 0.9913043478260869\n"
     ]
    }
   ],
   "source": [
    "# LogisticRegressionCV는 Cs 자체에서 교차검증을 하기 때문에 params에서 별도에 Cs를 지정할 필요가 없다.\n",
    "# 교차검증을 사용해 자동으로 최적의 해를 골라주는 모델이다.\n",
    "# 이번에는 iris 데이터셋을 사용해볼까요?\n",
    "from sklearn.datasets import load_iris\n",
    "iris_input = load_iris().data\n",
    "iris_target = load_iris().target\n",
    "\n",
    "train_input, test_input, train_target, test_target = train_test_split(iris_input,\n",
    "                                                                      iris_target,\n",
    "                                                                      stratify=iris_target)\n",
    "params = {\n",
    "    'solver' : ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'],\n",
    "    'penalty' : ['l1', 'l2', 'elasticnet', None]\n",
    "}\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "lr = LogisticRegressionCV()\n",
    "gs = GridSearchCV(estimator=lr,\n",
    "                 param_grid=params,\n",
    "                 scoring='accuracy',\n",
    "                 cv=5)\n",
    "gs.fit(train_input, train_target)\n",
    "print('가장 좋은 모델은 : {}'.format(gs.best_estimator_))\n",
    "print('그럴 때 정확도는 : {}'.format(gs.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "3f77df44-5feb-482e-9bdf-8366c304a0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9910714285714286\n",
      "0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "lrcv = LogisticRegressionCV(Cs=10, penalty='l1', solver='saga')\n",
    "lrcv.fit(train_input, train_target)\n",
    "print(lrcv.score(train_input, train_target))\n",
    "print(lrcv.score(test_input, test_target))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
